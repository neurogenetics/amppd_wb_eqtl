{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook to format genotypes for use with tensorQTL\n",
    "\n",
    "typically store wgs genotypes by chromosome in vcf or plink2 pfiles\n",
    "tensorQTL using plink1 bfiles, so convert, also since small cohort go ahead and merge from per chromosome to genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import libraries and set notebook variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "cohort = 'biofind'\n",
    "amp_abbr = 'BF'\n",
    "version = 'amppdv1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming\n",
    "cohort_version = f'{cohort}.{version}'\n",
    "\n",
    "# directories\n",
    "wrk_dir = f'/home/jupyter/{cohort}'\n",
    "geno_dir = f'{wrk_dir}/genotypes'\n",
    "expr_dir = f'{wrk_dir}/expression'\n",
    "info_dir = f'{wrk_dir}/sample_info'\n",
    "\n",
    "# input files\n",
    "pfiles = '{genodir}/{cohortversion}.chr{chr}'\n",
    "\n",
    "# output files\n",
    "genome_bfile = f'{geno_dir}/{cohort_version}.bfile'\n",
    "risk_bfile = f'{geno_dir}/{cohort_version}.risk.bfile'\n",
    "chr_detected_out_file = '{exprdir}/{cohortbuild}.detected.genes.chr{chr}'\n",
    "\n",
    "# constant values\n",
    "autosomes = [str(x) for x in list(range(1,23))]\n",
    "max_dist = 1000000\n",
    "capture_out = !(nproc)\n",
    "max_threads = int(capture_out[0])\n",
    "alpha_value = 0.05\n",
    "max_feature_cnt_parallel_load = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bash_cmd(this_cmd):\n",
    "    !{this_cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert from plink2 pfiles to plink bfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with concurrent.futures.ProcessPoolExecutor() as ppe:\n",
    "    for chrom in autosomes:\n",
    "        this_pfile = pfiles.format(genodir=geno_dir, cohortversion=cohort_version, chr=chrom)\n",
    "        this_cmd = f'plink2 --pfile {this_pfile} --make-bed --out {this_pfile}.bfile --silent'\n",
    "#         print(this_cmd)\n",
    "        ppe.submit(run_bash_cmd, this_cmd)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the files into a single plink binary set\n",
    "\n",
    "def frmt_merge_list_file(geno_dir, cohort_version, autosomes):\n",
    "    merge_file_set = f'{geno_dir}/bfile_merge-list.txt'\n",
    "    with open(merge_file_set, 'w') as file_handler:\n",
    "        for chrom in autosomes:\n",
    "            this_pfile = pfiles.format(genodir=geno_dir, cohortversion=cohort_version, chr=chrom)\n",
    "            file_handler.write(f'{this_pfile}.bfile\\n')\n",
    "    return merge_file_set\n",
    "\n",
    "def run_plink_bfile_merge(merge_file_set, genome_bfile):\n",
    "    this_cmd = f'plink --merge-list {merge_file_set} --make-bed --allow-no-sex \\\n",
    "    --silent --out {genome_bfile} --maf 0.01 --geno 0.05 --hwe 0.000001'\n",
    "    !{this_cmd}\n",
    "\n",
    "# merge the per chrom bfiles into a genome bfile\n",
    "merge_file_set = frmt_merge_list_file(geno_dir, cohort_version, autosomes)\n",
    "run_plink_bfile_merge(merge_file_set, genome_bfile)\n",
    "\n",
    "# if there was a missnp problem remove those variant and re-attemp merge\n",
    "if os.path.exists(f'{genome_bfile}-merge.missnp'):\n",
    "    print('removing problem variants and retrying merge')\n",
    "    with concurrent.futures.ProcessPoolExecutor() as ppe:\n",
    "        for chrom in autosomes:\n",
    "            this_pfile = pfiles.format(genodir=geno_dir, cohortversion=cohort_version, chr=chrom)\n",
    "            this_cmd = f'plink2 --pfile {this_pfile} --make-bed --out {this_pfile}.bfile \\\n",
    "--silent --exclude {genome_bfile}-merge.missnp'\n",
    "    #         print(this_cmd)\n",
    "            ppe.submit(run_bash_cmd, this_cmd)           \n",
    "\n",
    "    # try the merge again\n",
    "    merge_file_set = frmt_merge_list_file(geno_dir, cohort_version, autosomes)\n",
    "    run_plink_bfile_merge(merge_file_set, genome_bfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {genome_bfile}*\n",
    "!head {genome_bfile}.log\n",
    "!tail {genome_bfile}.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
