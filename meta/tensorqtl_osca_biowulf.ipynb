{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OSCA meta-QTL analysis\n",
    "\n",
    "##### https://cnsgenomics.com/software/osca/#Overview\n",
    "##### Zhang F, Chen W, Zhu Z, Zhang Q, Nabais, MF, Qi T, Deary IJ, Wray NR, Visscher PM, McRae AF, Yang J (2019) OSCA: a tool for omic-data-based complex trait analysis. Genome Biol, 20:107."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### April 28, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import argsort\n",
    "import dask.dataframe as dd\n",
    "import pyarrow.parquet as pq\n",
    "import csv\n",
    "import time\n",
    "from gtfparse import read_gtf\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories\n",
    "wrk_dir = f'/labshare/anni/eqtl/osca'\n",
    "script_dir = f'{wrk_dir}/scripts'\n",
    "tensorqtl_dir = f'{wrk_dir}/tensorqtl'\n",
    "results_dir = f'{wrk_dir}/results'\n",
    "\n",
    "# input files\n",
    "gencode_file1 = '/labshare/anni/eqtl/gencode.v32.annotation.gtf'\n",
    "gencode_file2 = '/labshare/raph/datasets/gtex/ExpressionFiles/gencode.v26.GRCh38.genes.gtf'\n",
    "\n",
    "# variables\n",
    "timept = 'BLM0T1'\n",
    "cell_types_list = ['Lymphocytes',\n",
    "                   'Neutrophils', 'Basophils',\n",
    "                   'Eosinophils','Monocytes']\n",
    "cohort_list = ['ppmi','pdbp']\n",
    "\n",
    "# biowulf variables\n",
    "username = 'mooreank'\n",
    "biowulf_dir = '/data/LNG/anni/osca'\n",
    "\n",
    "# constant values\n",
    "alpha_value = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##download osca and smr\n",
    "!wget https://cnsgenomics.com/software/osca/download/osca_Linux.zip\n",
    "!wget https://cnsgenomics.com/software/smr/download/smr_Linux.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copy over tensorqtl results files from the cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##tensorqtl parquet files\n",
    "!gsutil -m cp gs://nihnialngcbg-eqtl/ppmi/tensorqtl/* /labshare/anni/eqtl/tensorqtl_meta/ppmi/tensorqtl/\n",
    "!gsutil -m cp gs://nihnialngcbg-eqtl/pdbp/tensorqtl/* /labshare/anni/eqtl/tensorqtl_meta/pdbp/tensorqtl/\n",
    "#!gsutil -m cp gs://nihnialngcbg-eqtl/gtex/tensorqtl/* /labshare/anni/eqtl/tensorqtl_meta/gtex/tensorqtl/\n",
    "\n",
    "##geno info files\n",
    "!gsutil -m cp gs://nihnialngcbg-eqtl/ppmi/genotypes/ppmi.amppdv1.bfile.bim /labshare/anni/eqtl/tensorqtl_meta/ppmi/genotypes/\n",
    "!gsutil -m cp gs://nihnialngcbg-eqtl/pdbp/genotypes/pdbp.amppdv1.bfile.bim /labshare/anni/eqtl/tensorqtl_meta/pdbp/genotypes/\n",
    "#!gsutil -m cp gs://nihnialngcbg-eqtl/gtex/genotypes/gtex.v8.bfile.bim /labshare/anni/eqtl/tensorqtl_meta/gtex/genotypes/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove other tensorqtl results from the biowulf folder and add working timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timept = \n",
    "print('rm /data/LNG/anni/osca/tensorqtl/*')\n",
    "\n",
    "print(f'scp /labshare/anni/eqtl/tensorqtl_meta/ppmi/tensorqtl/ppmi.{timept}* {username}@helix.nih.gov:/{biowulf_dir}/tensorqtl/')\n",
    "print(f'scp /labshare/anni/eqtl/tensorqtl_meta/ppmi/tensorqtl/pdbp.{timept}* {username}@helix.nih.gov:/{biowulf_dir}/tensorqtl/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate esd, flist files to create besd files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##script generating esd files per gene\n",
    "\n",
    "##tensorqtl_osca_esd_cell.py\n",
    "# #def make_esd_files(cohort, version, cohort_build, cell_type):\n",
    "# cohort = 'pdbp'\n",
    "# version = 'amppdv1'\n",
    "# cohort_build = 'pdbp'\n",
    "# cell_type = 'Monocytes'\n",
    "# print(f'{cell_type}')\n",
    "# parquet_dir = f'/labshare/anni/eqtl/tensorqtl_meta/{cohort}/tensorqtl'\n",
    "# cell_files = f'{parquet_dir}/{cohort_build}.{cell_type}.cis_qtl_pairs.chr*.parquet'\n",
    "# cieqtl_df = dd.read_parquet(cell_files)\n",
    "# cieqtl_df = cieqtl_df.drop_duplicates()\n",
    "# cieqtl_df['new_gene'] = cieqtl_df['phenotype_id'].str.partition('.')[0]\n",
    "# probe_ids = list(set(cieqtl_df['new_gene']))\n",
    "# #probe_ids = cieqtl_df['new_gene'].tolist()\n",
    "# print(f'genes: {len(probe_ids)}')\n",
    "\n",
    "# #print(cieqtl_df.shape)\n",
    "# #display(cieqtl_df.head())\n",
    "# bim_dir = f'/labshare/anni/eqtl/tensorqtl_meta/{cohort}/genotypes'\n",
    "# genotype_df = dd.read_csv(f'{bim_dir}/{cohort}.{version}.bfile.bim', sep = '\\t', header=None)\n",
    "# genotype_df = genotype_df.rename(columns={0:'chr',1:'variant_id',3:'pos',4:'ref',5:'alt'})\n",
    "\n",
    "# genotype_df['variant_id'] = genotype_df['variant_id'].str.replace('_b38','')\n",
    "# genotype_df['variant_id'] = genotype_df['variant_id'].str.replace('_',':')\n",
    "# #genotype_df.head()\n",
    "\n",
    "# merge_df = dd.merge(cieqtl_df,genotype_df, on='variant_id')\n",
    "# #display(merge_df.head())\n",
    "# ##subset columns\n",
    "\n",
    "#updating gene ids from v26 to v32 when needed\n",
    "#read in gencode files\n",
    "# gencode = read_gtf(f'{gencode_file1}')\n",
    "# print('loaded gencode v32.')\n",
    "# gencode = gencode[gencode['feature'] == 'gene']\n",
    "# gencode[['new_gene','end']] = gencode['gene_id'].str.split('.',n=2,expand=True)\n",
    "# gencode = gencode[['gene_id','new_gene','seqname','strand','start']]\n",
    "# gen_gene = gencode['new_gene'].tolist()\n",
    "\n",
    "# # v26 = read_gtf(f'{gencode_file2}')\n",
    "# # print('loaded gencode v26.')\n",
    "# # v26 = v26[v26['feature'] == 'gene']\n",
    "# # v26[['new_gene','part']] = v26['gene_id'].str.split('.',expand=True)\n",
    "# # v26 = v26[['gene_id','new_gene','seqname','strand','start']]\n",
    "\n",
    "# ##get missing genes from v32\n",
    "# overlap = list(set(gen_gene) & set(probe_ids))\n",
    "# print(f'in v32: {len(overlap)}')\n",
    "# left = list(set(probe_ids) - set(overlap))\n",
    "# print(f'adding with v26: {len(left)}')\n",
    "\n",
    "#add v26 info to missing genes\n",
    "# left_v26 = merge_df[merge_df['new_gene'].isin(left)]\n",
    "# left_v26 = left_v26.merge(v26, on='new_gene')\n",
    "\n",
    "# merge_df = dd.merge(merge_df,gencode, on='new_gene', how='inner')\n",
    "# merge_df = merge_df.drop_duplicates()\n",
    "# # display(merge_df.head())\n",
    "# all_df = merge_df\n",
    "# #merge all genes with info\n",
    "# #all_df = dd.concat([merge_df,left_v26])\n",
    "# #print(all_df.shape)\n",
    "\n",
    "# esd_df = all_df[['gene_id','chr','variant_id','pos','ref','alt','maf','b_gi','b_gi_se','pval_gi']]\n",
    "# esd_df = esd_df.drop_duplicates()\n",
    "\n",
    "\n",
    "# ##convert to numpy array to speed up subsetting\n",
    "# all_array = esd_df.compute().to_numpy()\n",
    "# new_ids = list(set([item[0] for item in all_array]))\n",
    "# all_array\n",
    "\n",
    "# print('subsetting genes...')\n",
    "# for gene in new_ids:\n",
    "#     ##make subset array per gene\n",
    "#     probe_array = all_array[np.in1d(all_array[:,0],gene)]\n",
    "\n",
    "#     ##remove gene id column \n",
    "#     #probe_array = np.delete(probe_array, 1, 0)\n",
    "#     probe_array = [i[1:] for i in probe_array]\n",
    "\n",
    "#     ##save to textfile\n",
    "#     filename = f'/labshare/anni/eqtl/tensorqtl_meta/{cohort}/osca/{cohort}.{cell_type}.{gene}.{cell_type}.esd'\n",
    "#     with open(filename,\"w+\") as my_csv:\n",
    "#         print('Chr\\tSNP\\tBp\\tA1\\tA2\\tFreq\\tBeta\\tse\\tp', file=my_csv)\n",
    "#         csvWriter = csv.writer(my_csv,delimiter='\\t')\n",
    "#         csvWriter.writerows(probe_array)\n",
    "\n",
    "# print(f'{cell_type}: done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make swarm file to make esd files for all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate swarm file to run in biowulf\n",
    "\n",
    "def make_esd_swarm(timept):\n",
    "    file = f'{script_dir}/wb.{timept}.make.esd.swarm'\n",
    "    with open(file, \"w\") as text_file:\n",
    "        for cohort in cohort_list:\n",
    "            for cell_type in cell_types_list:\n",
    "                text_file.write(f'python tensorqtl_osca_esd_cell.py {cohort} amppdv1 wb {cell_type} \\\n",
    "                > {cohort}.{cell_type}.log\\n')\n",
    "\n",
    "make_esd_swarm(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make flist file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_flist_file(cohort, version, cohort_build, cell_type):\n",
    "    parquet_dir = f'/labshare/anni/eqtl/tensorqtl_meta/{cohort}/tensorqtl'\n",
    "    cell_files = f'{parquet_dir}/{cohort_build}.{cell_type}.cis_qtl_pairs.chr*.parquet'\n",
    "    cieqtl_df = dd.read_parquet(cell_files)\n",
    "    cieqtl_df = cieqtl_df.drop_duplicates(subset=['phenotype_id'])\n",
    "    cieqtl_df['new_gene'] = cieqtl_df['phenotype_id'].str.partition('.')[0]\n",
    "    probe_ids = list(set(cieqtl_df['new_gene']))\n",
    "    print(f'genes: {len(probe_ids)}')\n",
    "    #display(cieqtl_df.head())\n",
    "\n",
    "    ##read in gencode files\n",
    "    gencode = read_gtf(f'{gencode_file1}')\n",
    "    print('loaded gencode v32.')\n",
    "    gencode = gencode[gencode['feature'] == 'gene']\n",
    "    #gencode[['gene','part']] = gencode['gene_id'].str.split('.',expand=True)\n",
    "    gencode['seqname'] = gencode['seqname'].str.replace(\"chr\", \"\")\n",
    "    #gencode = gencode.drop_duplicates(subset=['gene'])\n",
    "    gencode[['new_gene','end']] = gencode['gene_id'].str.split('.',n=2,expand=True)\n",
    "    gencode = gencode[['seqname','gene_id', 'strand','start','new_gene']]\n",
    "    gen_gene = gencode['new_gene'].tolist()\n",
    "\n",
    "    v26 = read_gtf(f'{gencode_file2}')\n",
    "    print('loaded gencode v26.')\n",
    "    v26 = v26[v26['feature'] == 'gene']\n",
    "    v26[['new_gene','part']] = v26['gene_id'].str.split('.',expand=True)\n",
    "    v26['seqname'] = v26['seqname'].str.replace(\"chr\", \"\")\n",
    "\n",
    "    ##get missing genes from v32\n",
    "    overlap = list(set(gen_gene) & set(probe_ids))\n",
    "    print(f'in v32: {len(overlap)}')\n",
    "    left = list(set(probe_ids) - set(overlap))\n",
    "    print(f'adding with v26: {len(left)}')\n",
    "\n",
    "    #add v26 info to missing genes\n",
    "    cieqtl_v26 = cieqtl_df[cieqtl_df['new_gene'].isin(left)]\n",
    "    cieqtl_v26 = cieqtl_v26.merge(v26, on='new_gene')\n",
    "    cieqtl_v26 = cieqtl_v26[['seqname','gene_id', 'strand','start','new_gene']]\n",
    "    #print(cieqtl_v26.shape)\n",
    "    #display(cieqtl_v26.head())\n",
    "\n",
    "    merge_df = dd.merge(cieqtl_df,gencode, on='new_gene', how='inner')\n",
    "    #merge all genes with info\n",
    "    all_df = dd.concat([merge_df,cieqtl_v26])\n",
    "    #print(all_df.shape)\n",
    "    #display(all_df.head())\n",
    "\n",
    "    # ##subset columns\n",
    "    all_df = all_df[['seqname','gene_id','start','strand']]\n",
    "    all_df = all_df.rename(columns={'seqname':'Chr','gene_id':'ProbeID','start':'ProbeBp','strand':'Orientation'})\n",
    "    all_df['GeneticDistance'] = '0'\n",
    "    all_df['Gene'] =  all_df['ProbeID']\n",
    "    all_df['Chr'] = all_df['Chr'].str.replace(\"chr\", \"\")\n",
    "    all_df['PathOfEsd'] = f'/data/LNG/anni/osca/besd_input/{cohort}.{cell_type}.'+all_df['ProbeID']+'.esd'\n",
    "    all_df = all_df[['Chr','ProbeID','GeneticDistance','ProbeBp','Gene','Orientation','PathOfEsd']]\n",
    "    a = all_df.shape\n",
    "    all_df = all_df.compute()\n",
    "    print(f'final shape: {a[0].compute(),a[1]}')\n",
    "    out_dir = f'/labshare/anni/eqtl/osca/besd_input'\n",
    "    all_df.to_csv(f'{out_dir}/{cohort}.{cell_type}.flist', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genes: 14921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracted GTF attributes: ['gene_id', 'gene_type', 'gene_name', 'level', 'hgnc_id', 'havana_gene', 'transcript_id', 'transcript_type', 'transcript_name', 'transcript_support_level', 'tag', 'havana_transcript', 'exon_number', 'exon_id', 'ont', 'protein_id', 'ccdsid']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded gencode v32.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracted GTF attributes: ['gene_id', 'transcript_id', 'gene_type', 'gene_name', 'transcript_type', 'transcript_name', 'level', 'havana_gene', 'exon_id', 'exon_number', 'tag']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded gencode v26.\n",
      "in v32: 14921\n",
      "adding with v26: 0\n",
      "final shape: (14921, 7)\n",
      "genes: 13810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracted GTF attributes: ['gene_id', 'gene_type', 'gene_name', 'level', 'hgnc_id', 'havana_gene', 'transcript_id', 'transcript_type', 'transcript_name', 'transcript_support_level', 'tag', 'havana_transcript', 'exon_number', 'exon_id', 'ont', 'protein_id', 'ccdsid']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded gencode v32.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracted GTF attributes: ['gene_id', 'transcript_id', 'gene_type', 'gene_name', 'transcript_type', 'transcript_name', 'level', 'havana_gene', 'exon_id', 'exon_number', 'tag']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded gencode v26.\n",
      "in v32: 13810\n",
      "adding with v26: 0\n",
      "final shape: (13810, 7)\n",
      "genes: 14921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracted GTF attributes: ['gene_id', 'gene_type', 'gene_name', 'level', 'hgnc_id', 'havana_gene', 'transcript_id', 'transcript_type', 'transcript_name', 'transcript_support_level', 'tag', 'havana_transcript', 'exon_number', 'exon_id', 'ont', 'protein_id', 'ccdsid']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded gencode v32.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracted GTF attributes: ['gene_id', 'transcript_id', 'gene_type', 'gene_name', 'transcript_type', 'transcript_name', 'level', 'havana_gene', 'exon_id', 'exon_number', 'tag']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded gencode v26.\n",
      "in v32: 14921\n",
      "adding with v26: 0\n",
      "final shape: (14921, 7)\n",
      "genes: 13810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracted GTF attributes: ['gene_id', 'gene_type', 'gene_name', 'level', 'hgnc_id', 'havana_gene', 'transcript_id', 'transcript_type', 'transcript_name', 'transcript_support_level', 'tag', 'havana_transcript', 'exon_number', 'exon_id', 'ont', 'protein_id', 'ccdsid']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded gencode v32.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracted GTF attributes: ['gene_id', 'transcript_id', 'gene_type', 'gene_name', 'transcript_type', 'transcript_name', 'level', 'havana_gene', 'exon_id', 'exon_number', 'tag']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded gencode v26.\n",
      "in v32: 13810\n",
      "adding with v26: 0\n",
      "final shape: (13810, 7)\n",
      "genes: 14921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracted GTF attributes: ['gene_id', 'gene_type', 'gene_name', 'level', 'hgnc_id', 'havana_gene', 'transcript_id', 'transcript_type', 'transcript_name', 'transcript_support_level', 'tag', 'havana_transcript', 'exon_number', 'exon_id', 'ont', 'protein_id', 'ccdsid']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded gencode v32.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracted GTF attributes: ['gene_id', 'transcript_id', 'gene_type', 'gene_name', 'transcript_type', 'transcript_name', 'level', 'havana_gene', 'exon_id', 'exon_number', 'tag']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded gencode v26.\n",
      "in v32: 14921\n",
      "adding with v26: 0\n",
      "final shape: (14921, 7)\n",
      "genes: 13810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracted GTF attributes: ['gene_id', 'gene_type', 'gene_name', 'level', 'hgnc_id', 'havana_gene', 'transcript_id', 'transcript_type', 'transcript_name', 'transcript_support_level', 'tag', 'havana_transcript', 'exon_number', 'exon_id', 'ont', 'protein_id', 'ccdsid']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded gencode v32.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracted GTF attributes: ['gene_id', 'transcript_id', 'gene_type', 'gene_name', 'transcript_type', 'transcript_name', 'level', 'havana_gene', 'exon_id', 'exon_number', 'tag']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded gencode v26.\n",
      "in v32: 13810\n",
      "adding with v26: 0\n",
      "final shape: (13810, 7)\n"
     ]
    }
   ],
   "source": [
    "##generate flist files\n",
    "for cell in cell_types_list:\n",
    "    make_flist_file('ppmi','amppdv1','ppmi',cell)\n",
    "    make_flist_file('pdbp','amppdv1','pdbp',cell)\n",
    "    #make_flist_file('gtex','v8','gtex.v8.wb',cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## set up osca commands\n",
    "# cohort_list = ['ppmi','pdbp']\n",
    "\n",
    "# #for cell in cell_types_list:\n",
    "# for cohort in cohort_list:\n",
    "#     for cell in cell_types_list:\n",
    "#         in_dir = f'/data/LNG/anni/osca/besd_input'\n",
    "#         out_dir = f'/data/LNG/anni/osca/besd_files'\n",
    "#         print(f'./smr_Linux --eqtl-flist {in_dir}/{cohort}.{cell}.flist --make-besd --out {out_dir}/{cohort}.{cell}')\n",
    "#     print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make swarm file to create besd files from esd, flist files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_besd_swarm(timept):\n",
    "    file = f'{script_dir}/wb.{timept}.make.besd.swarm'\n",
    "    with open(file, \"w\") as text_file:\n",
    "        for cohort in cohort_list:\n",
    "            for cell_type in cell_types_list:\n",
    "                text_file.write(f'{biowulf_dir}/smr_Linux --eqtl-flist {biowulf_dir}/besd_input/{cohort}.{cell_type}.flist\\\n",
    "                --make-besd --out {biowulf_dir}/besd_files/{cohort}.{timept}.{cell_type}\\n')\n",
    "\n",
    "make_besd_swarm(timept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make swarm files to upate besd files\n",
    "#### (Need to update samples sizes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_besd_swarm(timept):\n",
    "    file = f'{script_dir}/wb.{timept}.update.besd.swarm'\n",
    "    with open(file, \"w\") as text_file:\n",
    "        for cell_type in cell_types_list:\n",
    "            text_file.write(f'{biowulf_dir}/smr_Linux --beqtl-summary {biowulf_dir}/besd_files/ppmi.{timept}.{cell_type} \\\n",
    "--add-n 1193 --make-besd --out {biowulf_dir}/besd_files/ppmi.{timept}.{cell_type}.test\\n')\n",
    "            text_file.write(f'{biowulf_dir}/smr_Linux --beqtl-summary {biowulf_dir}/besd_files/pdbp.{timept}.{cell_type} \\\n",
    "--add-n 1221 --make-besd --out {biowulf_dir}/besd_files/pdbp.{timept}.{cell_type}.test\\n')\n",
    "\n",
    "update_besd_swarm(timept)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timept = 'BLM0T1'\n",
    "# cell_type = 'Lymphocytes'\n",
    "# print(f'{biowulf_dir}/smr_Linux --beqtl-summary {biowulf_dir}/besd_files/ppmi.{cell_type} \\\n",
    "# --add-n 1193 --make-besd --out {biowulf_dir}/besd_files/ppmi.{timept}.{cell_type}')\n",
    "# print(f'{biowulf_dir}/smr_Linux --beqtl-summary {biowulf_dir}/besd_files/pdbp.{cell_type} \\\n",
    "# --add-n 1221 --make-besd --out {biowulf_dir}/besd_files/pdbp.{timept}.{cell_type}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prep for meta analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##make file list\n",
    "cohort_list = ['ppmi','pdbp']\n",
    "\n",
    "def make_cell_besd_list(timept):\n",
    "    for cell in cell_types_list:\n",
    "        file = f'{script_dir}/wb.{timept}.{cell}.besd.flist'\n",
    "        with open(file, \"w\") as text_file:\n",
    "            for cohort in cohort_list:\n",
    "                text_file.write(f'{biowulf_dir}/besd_files/{cohort}.{timept}.{cell}\\n')\n",
    "            #print(f'{file} &')\n",
    "\n",
    "\n",
    "make_cell_besd_list(timept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make swarm file to run meta analysis for all cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run meta analysis\n",
    "\n",
    "def make_meta_list(cell_list, timept):\n",
    "    file = f'{script_dir}/wb.{timept}.run.meta.swarm'\n",
    "    with open(file, \"w\") as text_file:\n",
    "        for cell in cell_list:\n",
    "            text_file.write(f'{biowulf_dir}/osca_Linux --besd-flist {biowulf_dir}/meta_scripts/wb.{timept}.{cell}.besd.flist \\\n",
    "            --meta --out {biowulf_dir}/results/wb.{timept}.{cell}\\n')\n",
    "#     with open(file, \"w\") as text_file:\n",
    "# print(f'./osca_Linux --besd-flist /data/LNG/anni/osca/meta_scripts/wb.{cell_type}.besd.flist \\\n",
    "# --meta --out /data/LNG/anni/osca/results/wb.{cell_type} &\\n')\n",
    "\n",
    "\n",
    "\n",
    "make_meta_list(cell_types_list, timept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy over generated files to biowulf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scp /labshare/anni/eqtl/osca/*_Linux mooreank@helix.nih.gov:/data/LNG/anni/osca/\n",
      "scp /labshare/anni/notebooks/eqtl/meta/tensorqtl_osca_esd_cell* mooreank@helix.nih.gov:/data/LNG/anni/osca/meta_scripts/\n",
      "scp /labshare/anni/eqtl/osca/scripts/* mooreank@helix.nih.gov:/data/LNG/anni/osca/meta_scripts/\n",
      "scp /labshare/anni/eqtl/osca/besd_input/*flist mooreank@helix.nih.gov:/data/LNG/anni/osca/besd_input/\n"
     ]
    }
   ],
   "source": [
    "## copy over files to biowulf\n",
    "\n",
    "#copy over tools\n",
    "print(f'scp {wrk_dir}/*_Linux {username}@helix.nih.gov:{biowulf_dir}/')\n",
    "\n",
    "#copy ove scripts\n",
    "print(f'scp /labshare/anni/notebooks/eqtl/meta/tensorqtl_osca_esd_cell* {username}@helix.nih.gov:{biowulf_dir}/meta_scripts/')\n",
    "print(f'scp {script_dir}/* {username}@helix.nih.gov:{biowulf_dir}/meta_scripts/')\n",
    "print(f'scp {wrk_dir}/besd_input/*flist {username}@helix.nih.gov:{biowulf_dir}/besd_input/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate osca commands to run in biowulf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run swarm to create esd files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swarm -f wb.BLM0T1.make.esd.swarm -g 50 --module python --time 24:00:00\n"
     ]
    }
   ],
   "source": [
    "print(f'swarm -f wb.{timept}.make.esd.swarm -g 50 --module python --time 24:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run swarm to create besd files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swarm -f wb.BLM0T1.make.besd.swarm -g 50 --time 04:00:00\n"
     ]
    }
   ],
   "source": [
    "print(f'swarm -f wb.{timept}.make.besd.swarm -g 50 --time 04:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swarm -f wb.BLM0T1.update.besd.swarm -g 50 --time 04:00:00\n"
     ]
    }
   ],
   "source": [
    "##run to update sample size in besd file\n",
    "\n",
    "print(f'swarm -f wb.{timept}.update.besd.swarm -g 50 --time 04:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run meta analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swarm -f wb.BLM0T1.run.meta.swarm -g 50 --time 04:00:00\n"
     ]
    }
   ],
   "source": [
    "print(f'swarm -f wb.{timept}.run.meta.swarm -g 50 --time 04:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### look at results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get results\n",
    "def get_top_snps(time):\n",
    "    file = f'{script_dir}/wb.{timept}.top.results.swarm'\n",
    "    with open(file, \"w\") as text_file:\n",
    "        for cell_type in cell_types_list:\n",
    "            text_file.write(f'/data/LNG/anni/osca/smr_Linux --beqtl-summary {biowulf_dir}/results/wb.{timept}.{cell_type} \\\n",
    "    --query {alpha_value} --out {biowulf_dir}/results/wb.{timept}.{cell_type}.top_assoc\\n')\n",
    "\n",
    "get_top_snps(timept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swarm -f wb.BLM0T1.top.results.swarm -g 20\n"
     ]
    }
   ],
   "source": [
    "print(f'swarm -f wb.{timept}.top.results.swarm -g 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
